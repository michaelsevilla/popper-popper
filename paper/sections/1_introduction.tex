\section{Introduction}

\section{Popper-compliant Papers}

% what papers have we done
We have authored five Popper-compliant papers:
\begin{itemize}

\item quiho: Automated Performance Regression Testing Using Inferred
Resource Utilization Profiles~\cite{}

\item Cudele: An API and Framework for Programmable Consistency and
Durability in a Global Namespace~\cite{sevilla:ipdps18-cudele}

\item Malacology: A Programmable Storage
System~\cite{sevilla:eurosys17-malacology}

\item Characterizing and Reducing Cross-Platform Performance Using
OS-level Virtualization

\item Programmable Caches with a Data Management Language \& Policy Engine

\end{itemize}

We use the reader/reviewer sample workflow outlined
in~\cite{jimenez:ipdpsw17-popper} and shown in Figure~\ref{fig:workflow}. For
the visualization component (1), we use Jupyter notebooks. The notebooks
themselves are versioned with Git and users interact with local copies by
cloning the repository and launching a Jupyter Docker container. The paper is
written in \LaTeX and built with a Docker container.  For the code component
(2), both the source code for the system itself and the deploy/experiment code
is stored on GitHub. When running experiments, we use Docker containers to
isolate libraries and binaries. For the multi-node component (3), we use
CloudLab machines and Ansible to script deployment and experiment
orchestration. For the data set components (4), we use GitHub to store results
files; our inputs and results are small enough that we do no need a larger
capacity.  GitHub allows files up to 50MB and stores data on S3.

\begin{figure}[tb] 
  \centering
  \includegraphics[width=1\linewidth]{./figures/workflow.png}
  \caption{Illustration of the Popper workflow used in our papers; Figure is
adapted from~\cite{jimenez:ipdpsw17-popper}. For (1) - the visualization
component - we use Jupyter, \LaTeX, and Docker; for (2) - the code component -
we use GitHub and Docker; for (3) - the multi-node component - we use Ansible
and CloudLab; and for (4) - the data set component - we use GitHub.}
  \label{fig:workflow}
\end{figure}

Our experiments start with a baseline; to describe the process, we reference
our
\href{https://github.com/michaelsevilla/ceph-popper-template}{ceph-popper-template}
set up on CloudLab. Users setup SSH keys and deploy CloudLab nodes using our
\href{https://www.cloudlab.us/p/CephFS/CephFS-HEP}{CephFS Profile}.  The
profile has the nodes automatically install Docker on bootup using our
\href{https://github.com/michaelsevilla/ceph-popper-template/blob/master/hardware/cloudlab/install.sh}{install}
script. After the nodes finish booting (i.e.  their status on the CloudLab GUI
read as READY), users push SSH keys using a convenience
\href{https://raw.githubusercontent.com/michaelsevilla/ceph-popper-template/master/hardware/cloudlab/pushkeys.sh}{script}.

The deploy code is based on
\href{https://github.com/ceph/ceph-ansible/wiki}{ceph-ansible}, a tool that
configures hardware and software for Ceph. We forked the project and made it
less dependent on Python. To run an experiment, users log in into the head node
and clone the ceph-popper-template. This repository has submodules that point
to ceph-ansible and our own custom roles; configuration files for our Ceph
setup; and helper scripts written in bash that deploy Ceph and run the
benchmarks. An outline of this organization is shown in
Figure~\ref{fig:expdir}.  For more information, see the
\href{https://github.com/michaelsevilla/ceph-popper-template}{README}. For more
information on the baseline and pipelines terminology, read more on the
\href{http://falsifiable.us/}{Popper Convention}. Then users configure their
cluster by specificing IPs and user names in the \texttt{hosts} file. 

\begin{figure}[tb] 
  \centering
  \includegraphics[width=1\linewidth]{./figures/expdir.png}
  \caption{Organization of our experiment directories. \texttt{baseline/} is an
example experiment and contains scripts populated with the Popper CLI. The
\texttt{run.sh} script uses many directories and files to setup and run
experiments, as indicated by the dashed lines.}
  \label{fig:expdir}
\end{figure}



Finally, users specify the Ceph services that should be deployed using the
\href{https://github.com/michaelsevilla/ceph-popper-template/tree/master/pipelines/baseline/ansible}{\texttt{ansible/}}
directory. This directory has code for deploying Ceph and its components:
\texttt{ansible.cfg}, \texttt{ceph.yml}, \texttt{cleanup.yml},
\texttt{group\_vars}, \texttt{monitor.yml}, and \texttt{workloads}. The *.yml
files are Ansible playbooks that start and configure components: ceph.yml
starts Ceph, cleanup.yml tears Ceph down, and monitor.yml starts daemons that
monitor performance. We separate these components into different playbooks so
users can mix and match Ceph services. The workloads directory has scrips for
running the baseline benchmarks. The other files and directories are Ansible
configuration files used by the playbooks.

Users can change the ansible/ceph.yml to specify which Ceph daemons to launch
in the cluster. It uses the hosts file we set up above and is based off the
ceph-ansible site file. High level configurations are in the vars.yml. This
file is heavily commented. For CloudLab, uncomment all blocks labeled
``Uncomment for CloudLab".

To configure the Ceph cluster with the variables in the Ceph configuration file
\href{http://docs.ceph.com/docs/jewel/rados/configuration/ceph-conf/}{documentation},
change the Ansible \texttt{group\_vars/all} file. We also need to specify the
Docker image. These can be specified in each configuration file for the daemon
but for simplicity we put everything in the global variable file. Finally,
users run the \texttt{run.sh} script. 

%% describe paper repository
%As an example, we use our Cudele publication~\cite{sevilla:ipdps18-cudele}. 
%
%
%\noindent \textbf{Paper Directory}: The
%\href{https://github.com/systemslab/cudele-popper/tree/master/paper}{paper
%directory} houses figures, bibliography, and \LaTeX source code. We use a
%common
%\href{https://github.com/michaelsevilla/biblio/tree/ee5f0d6744945fbcc5ddeaf8f5dbb86e1b8f8353}
%{bibliography} across papers, maintained in a separate repository so we have a
%submodule linked. The
%\href{https://github.com/systemslab/cudele-popper/blob/master/paper/build.sh}{build}
%script launches a \LaTeX Docker container and builds the PDF; different PDF
%versions, including our revisions and rebuttals can also be found in this
%`paper` directory.\\
%
%\noindent \textbf{Experiment Directory}: The
%\href{https://github.com/systemslab/cudele-popper/tree/master/experiments}{experiment
%directory} has all the experimental setup scripts, results, and visualizations.
%For example, the
%\href{https://github.com/systemslab/cudele-popper/tree/master/experiments/cudele-mergescale}{merge
%scale} experiment, in addition to the Popper \texttt{*.sh} script, has the
%following directories:
%
%\begin{itemize}
%  \item \texttt{ansible/}: experiment-specific deploy and benchmarking code, written in Ansible
%  \item \texttt{configs\_*/}: configuration code for CloudLab and our internal cluster named Piha.
%  \item \texttt{docker/}: experiment-specific images for housing and distributing source code
%  \item \texttt{results-*/}: results produced by the \texttt{run.sh} script
%  \item \texttt{visualize/}: Jupyter notebooks for viewing and interacting with results`
%\end{itemize}
%
%The actual workflow is shown in Figure~\ref{}. Users change to the directory,
%configure their cluster (using hte \texttt{configs\_*/} directory and
%\texttt{hosts} )

% degrees of popperization

\section{Popper Best Practices}

To produce Popper-compliant papers, we needed to change our workflows and
experimental procedures. We have learned the following lessons:

\subsection{Reproducibility Must Be a 1st Class Citizen}

% exploration vs. complete
Popper-compliance must be observed {\it throughout} the paper-writing process.
Attempts to make published papers Popper-compliant failed for three reasons:
(1) there is no incentive from the perspective of a graduate student, (2) it is
too hard to remember the experimental workflow, and (3) the artifacts cannot be
added to the camera-ready article. This introduces a careful design decision:
how does the user decide which results are exploratory and which are complete;
we do not want to waste space by saving results that do not contribute to the
paper but, at the same time, how do we know when an experiment is worthy of
being included in the paper? Discipline must be exercised throughout the paper-writing
process to make any experiment that we find useful must be immediately polished
to be Popper-compliant.

% cross-cluster compatibility 
Another pitfall we face is cross-cluster compatibility. After identifying
results as being useful, we usually find inventory files hard-coded throughout
the tree, configuration files randomly propagated to different directories,
visualization files reliant on data specified with hard-coded paths, and graphs
are not created automatically. To address this, we must exercise discipline to
separate cluster-specific files from cluster-agnostic files; we do this with
\texttt{configs\_*/} directories in our ceph-popper-template repository.

% organized repos/docs
Finally, organization and documentation must be required throughout the
paper-writing process. We fail to do this in early papers and this causes the
most work later on. System and experiment deploy code is rarely
self-explanatory. At a minimum, each experiment directory must contain a README
specifying how to run the jobs. To address this, we recommend relying heavily
on DockerHub, GitHub, and collaboration; making things public incentives
tidiness and organization. Using internal Docker or Git repositories hampers
Popper-compliance and discourages community involvement.

\subsection{Well-Defined Collaboration Roles}

% keeping organization workflows
Collaboration obviously speeds up code development and, As stated in the
previous section, collaboration can be used as motivation to keeping
Popper-compliant repositories; but collaboration can also hamper the process.
Researchers have different workflows and preferences. Committing system and
experimental deploy code with different toolkits, documentation, and styles to
the same repository results can result in a confusing organizational structure.
To address this, we recommend that the first author of the paper (1) produce a
style guide, either by committing a couple of experiments or adding detailed
READMEs and (2) act as the gatekeeper for all code. We recommend using GitHub
because it nicely formats READMEs and supports pull requests, issue trackers,
and project boards. Rather than having meetings to agree on experiment
organization, we recommend iteratively combining code from collaborators with
pull requests so the repository grows organically and quickly in the style
approved by the first author.

% merge conflicts
Another obstacle of collaboration is merge conflicts, especially when editing
the paper. We used to assign locks to people, in an {\it ad hoc} fashion over
email; this is not scalable. Instead, we now use Git to manage conflicts.
Before issuing a pull request, which notifies the first author, GitHub will
notify committers of changes they made in parallel with other changes. Our
policy is to force committers to resolve these merge conflicts before bothering
the first the author. While we still recommend issuing pull requests to make
sure the first author approves of the style, the merge conflicts workflow has
been an effective way to avoid annoying the first author with destructive
changes.

\subsection{Maintaining Pointers}

\begin{itemize}
  \item wary of ephemeral links

  \item large code bases large code bases (src, deploy)

  \item different registry hubs (Docker, GitHub)
\end{itemize}

\section{Community Cooperation}

\subsection{Conference Requirements}
% double blinded??

\subsection{Industry/Laboratory Requirements}
% private systems?

\section{Conclusion}
